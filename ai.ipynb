{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 32-bit"
  },
  "interpreter": {
   "hash": "571bacba9a29d47d526870ce679dff83b29c24567c7b1ef6e20c2daefc5a9ce9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Part A > Time Series Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Data Manipulation Dependencies\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "# Graphing Dependencies\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "# Time Series Dependency\r\n",
    "import statsmodels as sm\r\n",
    "\r\n",
    "# \r\n",
    "from sklearn.cluster import KMeans"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from statsmodels.tsa.stattools import adfuller\r\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv('./data/train.csv')\r\n",
    "df['Date'] = pd.to_datetime(df['Date'])\r\n",
    "df.sort_values('Date')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df['T'][df['T'] < 0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gbo = df.set_index(keys='Date').resample(rule='2M').mean()\r\n",
    "\r\n",
    "fig, ax = plt.subplots()\r\n",
    "plt.plot(gbo.index, gbo['T'], label='T')\r\n",
    "plt.plot(gbo.index, gbo['RH'], label='RH')\r\n",
    "\r\n",
    "ax2 = ax.twinx()\r\n",
    "plt.plot(gbo.index, gbo['Value'], label='Value', color='green')\r\n",
    "ax.legend()\r\n",
    "ax2.legend()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_(df):\r\n",
    "    # fig, ax = plt.subplots(nrows=2, ncols=2)\r\n",
    "    gb = df.groupby(by='Gas', as_index=False)\r\n",
    "    mean_ = gb.mean()\r\n",
    "    mean_['Type'] = ['Mean'] * mean_.shape[0]\r\n",
    "    types = ['Mean', 'Median']\r\n",
    "    comb_df = pd.DataFrame()\r\n",
    "    for i, frame in enumerate([gb.mean(), gb.median()]):\r\n",
    "        tmp_df = frame\r\n",
    "        tmp_df['Type'] = types[i]\r\n",
    "        comb_df = pd.concat(objs=(comb_df, tmp_df), axis=0)\r\n",
    "    # print(pd.merge(left=gb.mean(), right=gb.median(), on='Gas'))\r\n",
    "    print(comb_df)\r\n",
    "    sns.barplot(data=comb_df, x='Gas', y='Value', hue='Type', palette='rainbow')\r\n",
    "plot_(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_stationarity_of_columns(df: pd.DataFrame, significance_level: float = 0.01):\r\n",
    "    for col in df.drop(columns='Date').columns:\r\n",
    "        if df[col].dtype.kind in 'biufc':\r\n",
    "            p_value = round(adfuller(df.set_index(keys='Date')[col])[1], 5)\r\n",
    "            if p_value < significance_level:\r\n",
    "                print(f'{col}:\\tStationary ({p_value})'.expandtabs(tabsize=10))\r\n",
    "            else:\r\n",
    "                print(f'{col}:\\tNon-Stationary ({p_value})'.expandtabs(tabsize=10))\r\n",
    "            seasonal_decompose(df.copy().set_index(keys='Date')[col].resample(rule='D').sum()).plot()\r\n",
    "\r\n",
    "get_stationarity_of_columns(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
    "\r\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\r\n",
    "    def fit(self, X):\r\n",
    "        return self\r\n",
    "    \r\n",
    "    def transform(self, X):\r\n",
    "        X['Year'] = pd.DatetimeIndex(X['Date']).year\r\n",
    "        X['Month'] = pd.DatetimeIndex(X['Date']).month\r\n",
    "        X['Day'] = pd.DatetimeIndex(X['Date']).day\r\n",
    "        X['Quarter'] = pd.DatetimeIndex(X['Date']).quarter\r\n",
    "        return X"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "CustomTransformer().fit_transform(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df['Year'] = pd.DatetimeIndex(df['Date']).year\r\n",
    "df['Month'] = pd.DatetimeIndex(df['Date']).month\r\n",
    "df['Day'] = pd.DatetimeIndex(df['Date']).day\r\n",
    "df['Quarter'] = pd.DatetimeIndex(df['Date']).quarter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.groupby(by=['Year', 'Quarter']).count()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.scatterplot(data=df, x='Day', y='Value', hue='Month')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import Lasso, LinearRegression, Ridge\r\n",
    "from sklearn.ensemble import GradientBoostingRegressor, BaggingRegressor\r\n",
    "from sklearn.tree import DecisionTreeRegressor\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "model = BaggingRegressor()\r\n",
    "df['Gas'] = LabelEncoder().fit_transform(df['Gas'])\r\n",
    "\r\n",
    "model.fit(X=df.drop(columns=['Value', 'Date', 'Quarter']), y=df['Value'])\r\n",
    "pred = model.predict(X=df.drop(columns=['Value', 'Date', 'Quarter']))\r\n",
    "\r\n",
    "from sklearn.metrics import r2_score\r\n",
    "r2_score(df['Value'], pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test = pd.read_csv('./data/test.csv', index_col='id')\r\n",
    "CustomTransformer().transform(test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part B > Clustering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Exclusive Dependencies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.decomposition import PCA\r\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df2 = pd.read_csv('./data/Mall_Customers.csv', index_col=0)\r\n",
    "df2.rename(mapper={'Genre': 'Gender'}, axis=1, inplace=True)\r\n",
    "df2.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "['Eigenvalue', 'Explained Variance', 'Cumulative Explained Variance'].extend(df2.drop(columns='Gender').columns.tolist())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from typing import Union, List\r\n",
    "\r\n",
    "def get_pca_results(df: pd.DataFrame, ignore_cols: Union[str, List[str]]):\r\n",
    "    df_scaled = StandardScaler().fit_transform(X=df.drop(columns=ignore_cols))\r\n",
    "\r\n",
    "    pca = PCA(n_components=df_scaled.shape[1]).fit(X=df_scaled)\r\n",
    "    header = ['Eigenvalue', 'Explained Variance', 'Cumulative Explained Variance']\r\n",
    "    header.extend(df.drop(columns=ignore_cols).columns.tolist())\r\n",
    "    eigenvalues = pca.explained_variance_\r\n",
    "    eigenvectors = pca.components_\r\n",
    "    expl_var = pca.explained_variance_ratio_\r\n",
    "    cum_expl_var = pca.explained_variance_ratio_.cumsum()\r\n",
    "    pca_results = pd.DataFrame(\r\n",
    "        data=np.hstack((\r\n",
    "            eigenvalues.reshape(-1, 1),\r\n",
    "            expl_var.reshape(-1, 1),\r\n",
    "            cum_expl_var.reshape(-1, 1),\r\n",
    "            eigenvectors\r\n",
    "        )),\r\n",
    "        columns=header,\r\n",
    "        index=[f'PC {i + 1}' for i in range(df_scaled.shape[1])]\r\n",
    "    )\r\n",
    "\r\n",
    "    df_transformed = pd.DataFrame(\r\n",
    "        data=pca.transform(df_scaled),\r\n",
    "        index=df.index,\r\n",
    "        columns=[f'PC {i + 1}' for i in range(df_scaled.shape[1])]\r\n",
    "    )\r\n",
    "\r\n",
    "    return pca_results, df_transformed\r\n",
    "\r\n",
    "pca_results, df2_transformed = get_pca_results(df=df2, ignore_cols='Gender')\r\n",
    "pca_results"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def scree_plot(df: pd.DataFrame, pca: pd.DataFrame):\r\n",
    "    with sns.axes_style(style='darkgrid'):\r\n",
    "        ax = sns.pointplot(data=pca, x=pca.index, y=pca['Eigenvalue'])\r\n",
    "        ax.set(\r\n",
    "            title='Scree Plot for PCA (df2)',\r\n",
    "            ylim=(0, 1.4)\r\n",
    "        )\r\n",
    "        ax.annotate(text='As there is no elbow,\\nno PC should be discarded', xy=(1.75, 1.2), ha='center')\r\n",
    "        return ax\r\n",
    "\r\n",
    "scree_plot(df2, pca_results)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# type: ignore\r\n",
    "from sklearn.metrics import silhouette_score\r\n",
    "from itertools import combinations\r\n",
    "from more_itertools import powerset\r\n",
    "\r\n",
    "def get_silhouette_score_plot(df: pd.DataFrame, ignore_cols: Union[str, List[str]] = None):\r\n",
    "    ignore_cols = ignore_cols if ignore_cols is not None else [] \r\n",
    "    col_combs = filter(lambda x: len(x) == 3, list(powerset(df.drop(columns=ignore_cols).columns)))\r\n",
    "    \r\n",
    "    # n = len(cols)\r\n",
    "    # n = 10\r\n",
    "    # fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(10, 8))\r\n",
    "    # c = 0\r\n",
    "    fig, ax = plt.subplots()\r\n",
    "\r\n",
    "    sil = pd.DataFrame(data=list(range(2, 10)), columns=['Num'])\r\n",
    "    for col_comb in col_combs:\r\n",
    "        silhoutte_scores = []\r\n",
    "        col_list = [*col_comb]\r\n",
    "        for i in range(2, 10):\r\n",
    "            model = KMeans(n_clusters=i).fit(X=df[col_list])\r\n",
    "            y_hat = model.predict(X=df[col_list])\r\n",
    "            silhoutte_scores.append(silhouette_score(X=df[col_list], labels=y_hat))\r\n",
    "        col_str = ', '.join(col_list)\r\n",
    "\r\n",
    "        sil = pd.concat(objs=(sil, pd.Series(\r\n",
    "            name=col_str,\r\n",
    "            data=silhoutte_scores\r\n",
    "        )), axis=1)\r\n",
    "\r\n",
    "    # print(sil.melt(id_vars='Num'))\r\n",
    "    sns.lineplot(data=sil.melt(id_vars='Num'), x='Num', y='value', hue='variable', ax=ax)\r\n",
    "    \r\n",
    "    ax.legend(bbox_to_anchor=(2, 1))\r\n",
    "\r\n",
    "get_silhouette_score_plot(df=df2, ignore_cols='Gender')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cluster_params = [4, 5]\r\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 8))\r\n",
    "for i, cl in enumerate(cluster_params):\r\n",
    "    model = KMeans(n_clusters=cl).fit(X=df2[['Annual Income (k$)', 'Spending Score (1-100)']])\r\n",
    "    y_hat = model.predict(df2[['Annual Income (k$)', 'Spending Score (1-100)']])\r\n",
    "    sns.scatterplot(data=df2, x='Annual Income (k$)', y='Spending Score (1-100)', hue=y_hat, ax=ax[i])\r\n",
    "    print(f'Silhouette Score ({cl}):', silhouette_score(X=df2[['Annual Income (k$)', 'Spending Score (1-100)']], labels=model.labels_, metric='euclidean'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import plotly.express as px\r\n",
    "from sklearn.cluster import DBSCAN, OPTICS, AgglomerativeClustering, AffinityPropagation\r\n",
    "\r\n",
    "for mo in [KMeans(n_clusters=6), DBSCAN(eps=15, min_samples=15), OPTICS(max_eps=18)]:\r\n",
    "    colrs = mo.fit_predict(X=df2[['Annual Income (k$)', 'Age', 'Spending Score (1-100)']])\r\n",
    "    fig = px.scatter_3d(data_frame=df2, x='Annual Income (k$)', y='Age', z='Spending Score (1-100)', color=colrs, title=type(mo).__name__ + ' ' + str(round(silhouette_score(X=df2[['Annual Income (k$)', 'Age', 'Spending Score (1-100)']], labels=colrs), 2)), color_continuous_scale=px.colors.sequential.Rainbow)\r\n",
    "    fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}